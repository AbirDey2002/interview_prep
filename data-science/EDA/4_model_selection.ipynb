{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 4: Model Selection and Training üß†\n",
                "\n",
                "Once your data is engineered, compressed, and split, you've reached the main event: training the algorithm to learn patterns."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Algorithm Selection (Choosing Your Fighter) ü•ä\n",
                "\n",
                "You rarely train just one model. You select a few different types of algorithms to see which naturally understands your data best.\n",
                "\n",
                "### Common Algorithms for ZS Interviews\n",
                "\n",
                "| Algorithm | Type | When to Use | Why to Use It |\n",
                "| :--- | :--- | :--- | :--- |\n",
                "| **Linear Regression** | Regression | Predicting continuous numbers (sales, prices). | Highly interpretable; clear mathematical relationship. |\n",
                "| **Logistic Regression** | Classification | Predicting binary outcomes (Yes/No, Fraud/Not). | Outputs probabilities; great for stakeholder explanations. |\n",
                "| **Decision Trees** | Classification/Regression | Interpretable decisions. | Easy to visualize (flowchart style). |\n",
                "| **Random Forest** | Classification/Regression | Complex data with many features. | Robust, reduces overfitting, handles missing values well. |\n",
                "| **Gradient Boosting (XGBoost/LightGBM)** | Classification/Regression | Maximum predictive accuracy. | Iteratively learns from mistakes; top-performing for tabular data. |\n",
                "| **K-Means** | Clustering | Grouping customers/segments without labels. | Fast, scales well, drives business segmentation. |\n",
                "| **PCA** | Dimensionality Reduction | Compressing huge datasets. | Speeds up training and removes noise. |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Model Training (Fitting the Data) üõ†Ô∏è\n",
                "\n",
                "This is the learning part. Feed `X_train` (features) and `y_train` (labels) to the algorithm. The math works behind the scenes to assign weights and map relationships."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Deep Dive: Random Forest üå≤üå≤üå≤\n",
                "\n",
                "Instead of relying on one deep tree (which tends to overfit), a Random Forest builds hundreds of trees and combines their answers.\n",
                "\n",
                "### How It Works:\n",
                "1.  **Bootstrapping (Data Mixing) üé≤**: Creates mini-datasets by randomly sampling original training data.\n",
                "2.  **Random Features üîÄ**: Each tree is forced to choose splits from a random subset of features. This ensures diversity and prevents the strongest feature from dominating every tree.\n",
                "3.  **Aggregation (The Vote) üó≥Ô∏è**: \n",
                "    - **Regression**: Average of all tree predictions.\n",
                "    - **Classification**: Majority vote."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Implementation Example\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.model_selection import GridSearchCV\n",
                "\n",
                "# 1. Select the Algorithm\n",
                "model = RandomForestRegressor(random_state=42)\n",
                "\n",
                "# 2. Define Hyperparameters (The Dials)\n",
                "param_grid = {\n",
                "    'n_estimators': [50, 100],\n",
                "    'max_depth': [5, 10]\n",
                "}\n",
                "\n",
                "# 3. Set up Grid Search with 5-Fold Cross Validation\n",
                "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
                "\n",
                "# 4. Train the model\n",
                "# grid_search.fit(X_train, y_train)  # Uncomment in actual execution environment\n",
                "\n",
                "# 5. Check Results\n",
                "# print(f\"Best Settings Found: {grid_search.best_params_}\")\n",
                "# print(f\"Best Cross-Validation Score: {grid_search.best_score_:.4f}\")\n",
                "\n",
                "# 6. Save the best version of the model\n",
                "# best_model = grid_search.best_estimator_"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. How to Run the Model (Predictions) üöÄ\n",
                "\n",
                "Once you have the `best_model`, you can use it to predict outcomes on new, unseen data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make predictions using the final tuned model\n",
                "# predictions = best_model.predict(X_test)\n",
                "\n",
                "# For classification, you can also get probabilities\n",
                "# probabilities = best_model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "# Example of checking the first 5 predictions\n",
                "# print(predictions[:5])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
