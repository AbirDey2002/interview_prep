{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis (EDA) & Extracting Insights\n",
        "Once the data is clean, the goal is to understand its underlying patterns, relationships, and anomalies. EDA can be viewed as detective work: dusting for fingerprints, finding out-of-place clues, and seeing how they relate before model building."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Univariate Analysis & The Shape of Data üìä\n",
        "Looking at one variable at a time to understand its distribution.\n",
        "\n",
        "- **Histograms**: Group continuous data into bins to show the shape, central tendency, spread, and skewness of the distribution.\n",
        "- **Box Plots**: Visualize the spread and highlight outliers. It shows:\n",
        "  - Median (middle value)\n",
        "  - Interquartile range (middle 50% of the data)\n",
        "  - Whiskers (expected range)\n",
        "  - Outliers (dots outside whiskers)\n",
        "\n",
        "*Example*: If someone buys a $1,500 espresso machine while typical transactions are $4-$12, the average (mean) becomes distorted, making the median a much more reliable metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Multivariate Mysteries & Paradoxes üï∏Ô∏è\n",
        "Exploring relationships between two or more variables. Watch out for these traps:\n",
        "\n",
        "- **Correlation vs. Causation üìà**: Two variables moving together doesn't imply one causes the other (e.g., ice cream sales and sunburns are both driven by hot weather).\n",
        "- **Multicollinearity üëØ**: Input variables are highly correlated with each other, making it hard for models to isolate their individual impacts.\n",
        "- **Simpson's Paradox ü§Ø**: A trend appears in different groups but disappears or reverses when groups are combined (e.g., medical treatment success rates skewing when accounting for severity)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Verifying Correlation\n",
        "To verify if two features correlate, we use visual and mathematical tools.\n",
        "\n",
        "### Visual Verification üëÅÔ∏è\n",
        "- **Scatter Plots**: Plot features on X and Y axes.\n",
        "  - Line points up & right ‚Üí Positive correlation.\n",
        "  - Line points down & right ‚Üí Negative correlation.\n",
        "  - Random cloud ‚Üí No correlation.\n",
        "\n",
        "### Mathematical Verification üßÆ\n",
        "Correlation coefficient ranges from -1.0 to +1.0.\n",
        "- **Pearson Correlation ($r$)**: Measures strict linear relationships. Best for continuous, normally distributed data.\n",
        "\n",
        "$$r = \\frac{\\sum(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum(x_i - \\bar{x})^2 \\sum(y_i - \\bar{y})^2}}$$\n",
        "\n",
        "  - $x_i$ and $y_i$ are individual data points.\n",
        "  - $\\bar{x}$ and $\\bar{y}$ are the means of variables $x$ and $y$.\n",
        "\n",
        "- **Spearman Rank Correlation ($\\rho$)**: Measures monotonic relationships by comparing ranks of values instead of raw data. Robust to extreme outliers.\n",
        "\n",
        "$$\\rho = 1 - \\frac{6 \\sum d_i^2}{n(n^2 - 1)}$$\n",
        "\n",
        "  - $d_i$ is the difference between the ranks of corresponding values for $x$ and $y$.\n",
        "  - $n$ is the number of observations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Code Example: Correlation Matrix\n",
        "We can use pandas and seaborn to compute and visualize correlations across multiple features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'df' is your pandas DataFrame with multiple columns\n",
        "\n",
        "# 1. Calculate the Pearson correlation matrix\n",
        "pearson_matrix = df.corr(method='pearson')\n",
        "\n",
        "# 2. Calculate the Spearman correlation matrix\n",
        "spearman_matrix = df.corr(method='spearman')\n",
        "\n",
        "# 3. Visualize the Pearson matrix using a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(pearson_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.title(\"Pearson Correlation Heatmap\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Translating EDA into Business Insights üí°\n",
        "EDA helps frame ambiguous case studies logically by uncovering hidden clues.\n",
        "\n",
        "- **Segmentation & Cohort Analysis üç∞**: Averages hide the truth. Segmenting data reveals targeted insights (e.g., an AI tool's usage might be 10% overall but 60% for a specific medical specialty).\n",
        "- **Funnel & Bottleneck Analysis ‚è≥**: Mapping user journeys step-by-step to find exact drop-off points (e.g., 100% login, 90% prompt, but only 15% click reference links).\n",
        "\n",
        "These techniques allow you to form precise, actionable hypotheses for real-world business problems."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}